{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure you have the TweePy library installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure you have the TweePy library installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /opt/anaconda3/lib/python3.7/site-packages (from tweepy) (1.7.1)\n",
      "Requirement already satisfied: requests>=2.11.1 in /opt/anaconda3/lib/python3.7/site-packages (from tweepy) (2.22.0)\n",
      "Collecting requests-oauthlib>=0.7.0 (from tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->tweepy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 4.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.1.0 requests-oauthlib-1.2.0 tweepy-3.8.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure you have credentials for the Twitter API and set them here! [(See documentation here for help.)](http://docs.tweepy.org/en/v3.8.0/auth_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(\"putyour\", \"credentialshere\")\n",
    "auth.set_access_token(\"putyour\", \"credentialshere\")\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function to process Tweets and pull out relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(status):\n",
    "    \"\"\"\n",
    "    Takes in a Status object and returns a dictionary object of the post's most important information.\n",
    "    For this use case, that is:\n",
    "    - the set of hashtags present in the tweet, if any\n",
    "    - the full text of the tweet\n",
    "    - the link to the first piece of media embedded in the tweet, if any\n",
    "    - the name of the place (from the Place object of the Status), if any\n",
    "    - the timestamp of the tweet's creation\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    tags = []\n",
    "    for ht in status.entities['hashtags']:\n",
    "        tags.append(ht['text'])\n",
    "    data['hashtags'] = tags\n",
    "    data['full_text'] = status.full_text\n",
    "    media_link = \"n/a\"\n",
    "    if 'media' in status.entities.keys():\n",
    "        ent = status.entities['media'][0]\n",
    "        if ent['type'] == 'photo':\n",
    "            media_link = ent['expanded_url']\n",
    "    data['media_link'] = media_link\n",
    "    try:\n",
    "        data['place'] = status.place.full_name\n",
    "    except:\n",
    "        data['place'] = \"n/a\"\n",
    "    data['created_at'] = status.created_at\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the number of tweets you want and keywords you want to search for.\n",
    "#### The keywords do not need to be hashtags; in our case, most content about the wildfires was shared with each fire's hashtag so we used those hashtags to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wanted_tweets = 5000\n",
    "\n",
    "keywords = [\"#SaddleridgeFire\", \"#GettyFire\", \"#KincadeFire\", \"#MariaFire\", \"#EasyFire\", \"#TickFire\", \"#HillsideFire\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The search method can handle multiple keywords at the same time, so this cell creates the full query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#SaddleridgeFire OR #GettyFire OR #KincadeFire OR #MariaFire OR #EasyFire OR #TickFire OR #HillsideFire'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \" OR \".join(keywords)\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below takes in the number of desired tweets and the search query created above. It then loops through full-length English-language tweets and collects all non-retweet tweets in a list. Once it has collected all desired tweets, the loop breaks.\n",
    "#### There are a number of parameters that can be set (see documentation here for all information). In this case, we chose to filter based on language and on date, because we were aiming to gather information about specific fires (particularly Getty and Kincade, to illustrate certain components of our dashboard demo). Twitter's free API purportedly does not let you search further back than seven days, which would make reproducing our exact data pull difficult after the fact. However, someone using paid tiers of the Twitter API would have more options and ways to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulled 0 of 5000 tweets\n",
      "pulled 100 of 5000 tweets\n",
      "pulled 200 of 5000 tweets\n",
      "pulled 300 of 5000 tweets\n",
      "pulled 400 of 5000 tweets\n",
      "pulled 500 of 5000 tweets\n",
      "pulled 600 of 5000 tweets\n",
      "pulled 700 of 5000 tweets\n",
      "pulled 800 of 5000 tweets\n",
      "pulled 900 of 5000 tweets\n",
      "pulled 1000 of 5000 tweets\n",
      "pulled 1100 of 5000 tweets\n",
      "pulled 1200 of 5000 tweets\n",
      "pulled 1300 of 5000 tweets\n",
      "pulled 1400 of 5000 tweets\n",
      "pulled 1500 of 5000 tweets\n",
      "pulled 1600 of 5000 tweets\n",
      "pulled 1700 of 5000 tweets\n",
      "pulled 1800 of 5000 tweets\n",
      "pulled 1900 of 5000 tweets\n",
      "pulled 2000 of 5000 tweets\n",
      "pulled 2100 of 5000 tweets\n",
      "pulled 2200 of 5000 tweets\n",
      "pulled 2300 of 5000 tweets\n",
      "pulled 2400 of 5000 tweets\n",
      "pulled 2500 of 5000 tweets\n",
      "pulled 2600 of 5000 tweets\n",
      "pulled 2700 of 5000 tweets\n",
      "pulled 2800 of 5000 tweets\n",
      "pulled 2900 of 5000 tweets\n",
      "pulled 3000 of 5000 tweets\n",
      "pulled 3100 of 5000 tweets\n",
      "pulled 3200 of 5000 tweets\n",
      "pulled 3300 of 5000 tweets\n",
      "pulled 3400 of 5000 tweets\n",
      "pulled 3500 of 5000 tweets\n",
      "pulled 3600 of 5000 tweets\n",
      "pulled 3700 of 5000 tweets\n",
      "pulled 3800 of 5000 tweets\n",
      "pulled 3900 of 5000 tweets\n",
      "pulled 4000 of 5000 tweets\n",
      "pulled 4100 of 5000 tweets\n",
      "pulled 4200 of 5000 tweets\n",
      "pulled 4300 of 5000 tweets\n",
      "pulled 4400 of 5000 tweets\n",
      "pulled 4500 of 5000 tweets\n",
      "pulled 4600 of 5000 tweets\n",
      "pulled 4700 of 5000 tweets\n",
      "pulled 4800 of 5000 tweets\n",
      "pulled 4900 of 5000 tweets\n",
      "pulled 5000 of 5000 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=query,\n",
    "                           count=100, # the number of tweets to return from each page\n",
    "                           lang=\"en\", # the language of the tweet\n",
    "                           since=\"2019-10-03\", # optional field to filter search based on date (see note above)\n",
    "                           tweet_mode='extended').items():\n",
    "    if not tweet.full_text.startswith(\"RT @\"):\n",
    "        tweets.append(process_tweet(tweet))\n",
    "    if len(tweets) % 100 == 0:\n",
    "        print(f\"pulled {len(tweets)} of {num_wanted_tweets} tweets\")\n",
    "    if len(tweets) > num_wanted_tweets:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our dashboard demo (built in ARCGISOnline) is configured such that this dataset of tweets needs a specific `Disaster` column to designate which disaster each tweet is associated with. \n",
    "### In our case, this means each tweet needs to be associated with the correct `fire`. The following code turns the collected tweets into a dataframe, cleans the hashtags up, and creates the necessary column (`fire` in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saddleridge', 'Getty', 'Kincade', 'Maria', 'Easy', 'Tick', 'Hillside']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# providing the information necessary to filter and clean the tweets\n",
    "disaster_type = 'Fire'\n",
    "needed_disasters = [disaster.replace(disaster_type, \"\").replace(\"#\", \"\") for disaster in keywords]\n",
    "needed_disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets)\n",
    "\n",
    "# cleaning the hashtags up and creating the necessary disaster column\n",
    "df = df.explode('hashtags')\n",
    "df = df.loc[(df['hashtags'].str.contains(disaster_type)) | (df['hashtags'].str.contains(disaster_type.lower()))].copy()\n",
    "df[disaster_type.lower()] = df['hashtags'].str.replace(disaster_type, \"\")\n",
    "df[disaster_type.lower()] = df[disaster_type.lower()].str.replace(disaster_type.lower(), \"\")\n",
    "\n",
    "# in order to check for potential new disasters:\n",
    "# this is relevant in our use case because many new fires were starting even while we were working on this\n",
    "# df[disaster_type.lower()].value_counts()\n",
    "\n",
    "df = df.loc[df[disaster_type.lower()].isin(needed_disasters)]\n",
    "df = df[[disaster_type.lower(), 'full_text', 'media_link', 'place', 'created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fire', 'full_text', 'media_link', 'place', 'created_at'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire</th>\n",
       "      <th>full_text</th>\n",
       "      <th>media_link</th>\n",
       "      <th>place</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Saddleridge</td>\n",
       "      <td>From the #SaddleridgeFire to the #KincadeFire,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-27 19:59:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Saddleridge</td>\n",
       "      <td>Our hearts go out to Californians affected by ...</td>\n",
       "      <td>https://twitter.com/EPCFIRM/status/11885645126...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-27 21:13:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Saddleridge</td>\n",
       "      <td>@macayla_nield Hey, #SoCal, too, although, adm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-28 00:54:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Saddleridge</td>\n",
       "      <td>Smoke and flames poured from underground sewer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-28 02:29:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Saddleridge</td>\n",
       "      <td>The #SaddleridgeFire, which has burned about 4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-28 04:29:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fire                                          full_text  \\\n",
       "0  Saddleridge  From the #SaddleridgeFire to the #KincadeFire,...   \n",
       "1  Saddleridge  Our hearts go out to Californians affected by ...   \n",
       "2  Saddleridge  @macayla_nield Hey, #SoCal, too, although, adm...   \n",
       "3  Saddleridge  Smoke and flames poured from underground sewer...   \n",
       "4  Saddleridge  The #SaddleridgeFire, which has burned about 4...   \n",
       "\n",
       "                                          media_link place  \\\n",
       "0                                                NaN   NaN   \n",
       "1  https://twitter.com/EPCFIRM/status/11885645126...   NaN   \n",
       "2                                                NaN   NaN   \n",
       "3                                                NaN   NaN   \n",
       "4                                                NaN   NaN   \n",
       "\n",
       "            created_at  \n",
       "0  2019-10-27 19:59:04  \n",
       "1  2019-10-27 21:13:56  \n",
       "2  2019-10-28 00:54:08  \n",
       "3  2019-10-28 02:29:27  \n",
       "4  2019-10-28 04:29:21  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire</th>\n",
       "      <th>full_text</th>\n",
       "      <th>media_link</th>\n",
       "      <th>place</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5345</td>\n",
       "      <td>Kincade</td>\n",
       "      <td>Good Morning !.....after  the #KincadeFire ......</td>\n",
       "      <td>https://twitter.com/jonigeographer/status/1192...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 16:40:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5346</td>\n",
       "      <td>Kincade</td>\n",
       "      <td>California's Kincade Fire Burn Scar Seen From ...</td>\n",
       "      <td>https://twitter.com/SpaceRef/status/1192121602...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 16:48:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5347</td>\n",
       "      <td>Kincade</td>\n",
       "      <td>U.S. District Judge William Alsup ordered PG&amp;a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 17:04:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5348</td>\n",
       "      <td>Kincade</td>\n",
       "      <td>Kincade fire victims swarm county aid center i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 17:09:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5349</td>\n",
       "      <td>Kincade</td>\n",
       "      <td>@ETSshow Thanks for sharing @ETSshow . Been fe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 17:11:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fire                                          full_text  \\\n",
       "5345  Kincade  Good Morning !.....after  the #KincadeFire ......   \n",
       "5346  Kincade  California's Kincade Fire Burn Scar Seen From ...   \n",
       "5347  Kincade  U.S. District Judge William Alsup ordered PG&a...   \n",
       "5348  Kincade  Kincade fire victims swarm county aid center i...   \n",
       "5349  Kincade  @ETSshow Thanks for sharing @ETSshow . Been fe...   \n",
       "\n",
       "                                             media_link place  \\\n",
       "5345  https://twitter.com/jonigeographer/status/1192...   NaN   \n",
       "5346  https://twitter.com/SpaceRef/status/1192121602...   NaN   \n",
       "5347                                                NaN   NaN   \n",
       "5348                                                NaN   NaN   \n",
       "5349                                                NaN   NaN   \n",
       "\n",
       "               created_at  \n",
       "5345  2019-11-06 16:40:30  \n",
       "5346  2019-11-06 16:48:33  \n",
       "5347  2019-11-06 17:04:50  \n",
       "5348  2019-11-06 17:09:21  \n",
       "5349  2019-11-06 17:11:32  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick check of the percentage of tweets that actually contain media or location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "media_link    0.341308\n",
       "place         0.063551\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - df[['media_link', 'place']].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, the data is ready to be saved and passed into the ARCGISOnline dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_5k_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
